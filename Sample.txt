API Automation Framework - Comprehensive Documentation
1. Big Picture: What the Framework Does
This framework is built using Java, Maven, and RestAssured. It is designed to automate the testing of APIs by providing a structured and reusable architecture. The main objectives of this framework are to:

• Build and execute HTTP requests (GET, POST, PUT, DELETE, etc.) with support for authentication, headers, query parameters, cookies, and payloads.
• Validate responses by checking status codes, headers, payload data, and verifying against JSON/XML schemas.
• Organize multi-API scenarios into business flows that mimic real-world use cases.
• Provide data-driven testing by sourcing inputs from JSON, SQL, or Excel.
• Produce detailed logs and reports, which can be integrated with CI/CD pipelines and linked to TestRail for requirement/test case management.
• Maintain scalability and modularity so new APIs and scenarios can be added easily without impacting the existing code.
2. Execution Lifecycle
The framework follows a consistent lifecycle whenever a test is executed. This helps keep all tests standardized and ensures that setup, execution, and teardown are predictable.

Step 1: Start from a Runner
  - Tests are triggered from TestNG/JUnit runners. Suites are defined in XML under 'CISuite', allowing you to run smoke, regression, or custom test groups.

Step 2: Load Configuration and Environment
  - Environment-specific settings (base URLs, timeouts, credentials) are loaded from 'config.xml'. Logging configurations are read from 'log4j2.properties', while 'apis.json' defines endpoint metadata.

Step 3: Build the Request
  - Request builders in 'api/' use RestAssured to prepare the call. Constants in 'cons/' help manage endpoints. Core features such as retry policies, session management, and caching are implemented in 'core/'.

Step 4: Provide Test Data
  - Data for tests comes from JSON files in 'autodata/', SQL queries in 'TestCaseSqlQuery/', or parsers in 'dataparser/'. This ensures that tests are parameterized and reusable.

Step 5: Fire the Call and Validate
  - The request is executed and responses are validated using schemas located in 'jsonSchema/' or 'XMLSchema/'. Validation includes checking HTTP codes, headers, and payload contents.

Step 6: Report and Publish Results
  - After execution, logs and reports are generated. CI/CD pipelines can automatically run suites and publish results, while TestRail integration ensures traceability between tests and requirements.
3. Deep Dive by Folder
The framework is organized into specific folders, each with a clear responsibility:

• api/: Houses request builders that define how to interact with each endpoint.
• cons/: Contains constant values such as endpoints, resource names, and default parameters.
• core/: Includes core engine utilities like RestClient wrappers, retry policies, and session managers.
• dataparser/: Provides parsers for JSON, XML, or Excel data, converting them into Java objects.
• flow.rps/: Implements business workflows by chaining multiple API calls to form realistic scenarios.
• model/: Defines POJOs (Plain Old Java Objects) that represent request and response payloads.
• test/: Contains test cases that invoke API calls and assert expected outcomes.
• utils/: Offers utility methods for schema validation, file operations, payload comparison, and reporting.
4. src/test/resources
The resources folder contains essential supporting files:

• CISuite/: XML definitions of test suites used by CI/CD.
• jsonSchema/ and XMLSchema/: Canonical schemas to validate API responses.
• autodata/: JSON files holding parameterized test data.
• templates/: Request templates (JSON or Freemarker) used to generate dynamic payloads.
• TestCaseSqlQuery/: SQL files for data verification or setup.
• apis.json: Metadata definitions for endpoints.
• config.xml: Environment-specific configuration (URLs, timeouts).
• TestRailSectionMapping.properties: Maps test suites to TestRail sections.
• log4j2.properties: Configures logging format and levels.
5. Example Test Flow
Below is an example illustrating how a simple test is structured:

1) A request object (POJO) is created with the necessary parameters.
2) A request builder (from 'api/') is called with headers, authentication, and body.
3) The request is executed and the response captured.
4) Assertions are made on status code, headers, and schema validation.

6. Adding a New API Test
To add a new API test, follow these steps:

1) Define the endpoint in cons/ (Endpoints.java or apis.json).
2) Create request and response models in model/ with appropriate annotations.
3) Implement a request builder in api/ that supports the endpoint.
4) Add schema files to jsonSchema/ or XMLSchema/.
5) Prepare test data in autodata/ or TestCaseSqlQuery/.
6) Write the test in test/ to execute the call and assert results.
7) Include the test in an XML suite inside CISuite/ for CI/CD integration.
7. CI/CD and Reporting
The framework integrates seamlessly into CI/CD pipelines:

• Jenkins or AWS CodeBuild can trigger tests on every pull request or code merge.
• Different suites (smoke, regression, etc.) can be configured depending on the stage.
• Logs and reports are generated automatically.
• TestRail integration ensures that results are mapped to test cases, providing visibility into requirement coverage and execution trends.
8. Conventions and Best Practices
The framework follows a set of conventions to maintain readability and scalability:

• Naming conventions:
   - Tests: VerbResourceTest (e.g., UploadObjectTest)
   - API classes: ResourceApi
   - Models: ResourceRequest, ResourceResponse

• One API per class in api/.
• One schema per response type.
• One flow per business scenario.
• Use expressive assertion helpers (thenStatusIs, thenMatchesSchema) instead of inline assertions.
9. Quick Start Commands
Common Maven commands for executing tests:

• Run all tests: mvn clean test
• Run a suite: mvn -DsuiteXmlFile=src/test/resources/CISuite/smoke.xml test
• Run tests by group: configure groups in TestNG XML and run with -Dgroups=<groupName>
